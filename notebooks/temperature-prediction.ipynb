{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Autoregressive Temperature Prediction Demo\n",
    "\n",
    "This notebook demonstrates multi-step autoregressive prediction using the trained CNN-LSTM model.\n",
    "\n",
    "**Approach:**\n",
    "1. Load the trained model from `runs/2025-11-19_18-49-53/checkpoints/best_model.pt`\n",
    "2. Load ground truth frames from the test dataset\n",
    "3. Use first 3 frames as initial context\n",
    "4. Predict frame 4 using frames [1, 2, 3]\n",
    "5. Predict frame 5 using frames [2, 3, 4_predicted]\n",
    "6. Compare predictions vs ground truth and visualize error accumulation\n",
    "\n",
    "**Note:** Limited to 5 total frames (3 context + 2 predictions) due to test set size constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file in project root\n",
    "project_root = Path(\"../\").resolve()\n",
    "env_file = project_root / \".env\"\n",
    "if env_file.exists():\n",
    "    load_dotenv(dotenv_path=env_file, override=True)\n",
    "    print(f\"Loaded .env from: {env_file}\")\n",
    "else:\n",
    "    print(f\"Warning: .env file not found at {env_file}\")\n",
    "\n",
    "# Add project root to path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from lasernet.model.CNN_LSTM import CNN_LSTM\n",
    "from lasernet.dataset import SliceSequenceDataset\n",
    "\n",
    "data_dir = os.environ['BLACKHOLE']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "run_dir = Path(\"../runs/2025-11-19_18-49-53/\")\n",
    "checkpoint = torch.load(run_dir / \"checkpoints\" / \"best_model.pt\", map_location=device)\n",
    "config = json.loads((run_dir / \"config.json\").read_text())\n",
    "\n",
    "print(\"Checkpoint contents:\")\n",
    "print(f\"  Epoch: {checkpoint['epoch']}\")\n",
    "print(f\"  Train loss: {checkpoint['train_loss']:.4f}\")\n",
    "print(f\"  Val loss: {checkpoint['val_loss']:.4f}\")\n",
    "print(f\"  split_ratio: {config['dataset']['train_sequences']}\") # Todo\n",
    "\n",
    "# Initialize model with same architecture\n",
    "model = CNN_LSTM(\n",
    "    input_channels=1,\n",
    "    hidden_channels=[16, 32, 64],\n",
    "    lstm_hidden=64,\n",
    "    lstm_layers=1,\n",
    "    temp_min=300.0,\n",
    "    temp_max=2000.0,\n",
    ").to(device)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"  Parameters: {model.count_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Load Test Dataset\n",
    "\n",
    "We'll load a sequence of frames from the test set to use as ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset (using same configuration as training)\n",
    "test_dataset = SliceSequenceDataset(\n",
    "    field=\"temperature\",\n",
    "    plane=\"xz\",\n",
    "    split=\"test\",\n",
    "    sequence_length=3,\n",
    "    target_offset=1,\n",
    "    preload=False,  # Faster for demo\n",
    "    train_ratio=12/24,\n",
    "    val_ratio=6/24,\n",
    "    test_ratio=6/24,\n",
    ")\n",
    "\n",
    "print(f\"Test dataset loaded:\")\n",
    "print(f\"  Total samples: {len(test_dataset)}\")\n",
    "print(f\"  Valid sequences: {test_dataset.num_valid_sequences}\")\n",
    "print(f\"  Slices per timestep: {len(test_dataset.slice_coords)}\")\n",
    "print()\n",
    "\n",
    "# Get first sample to check dimensions\n",
    "sample = test_dataset[0]\n",
    "print(f\"Sample dimensions:\")\n",
    "print(f\"  Context: {sample['context'].shape}\")\n",
    "print(f\"  Target: {sample['target'].shape}\")\n",
    "print(f\"  Timesteps: {sample['timestep_start']} -> {sample['target_timestep']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. Prepare Ground Truth Sequence\n",
    "\n",
    "We need to extract consecutive frames from the same slice coordinate to form a continuous sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_initial_frames = 3   # Use first 3 frames as context (matches sequence_length)\n",
    "num_predictions = 3      # Predict next 3 frames autoregressively (limited by test set size)\n",
    "total_frames_needed = num_initial_frames + num_predictions\n",
    "\n",
    "print(f\"Loading {total_frames_needed} consecutive frames...\")\n",
    "print(f\"Test set has {test_dataset.num_valid_sequences} valid sequences\")\n",
    "\n",
    "# Load temperature data directly from preprocessed file\n",
    "import os\n",
    "data_dir = os.environ['BLACKHOLE']\n",
    "temp_path = os.path.join(data_dir, 'processed', 'temperature.pt')\n",
    "\n",
    "if os.path.exists(temp_path):\n",
    "    print(f\"Loading from preprocessed file: {temp_path}\")\n",
    "    temp_data = torch.load(temp_path, map_location='cpu')  # [T, X, Y, Z]\n",
    "    print(f\"Temperature data shape: {temp_data.shape}\")\n",
    "    \n",
    "    # Get test timestep range\n",
    "    num_timesteps = temp_data.shape[0]\n",
    "    test_start_idx = int((12/24) * num_timesteps) + int((6/24) * num_timesteps)\n",
    "    test_end_idx = num_timesteps\n",
    "    \n",
    "    print(f\"Test timesteps: {test_start_idx} to {test_end_idx-1}\")\n",
    "    print(f\"Available test timesteps: {test_end_idx - test_start_idx}\")\n",
    "    \n",
    "    # Extract XZ slice (same plane as training)\n",
    "    # For XZ plane, we iterate over Y coordinates\n",
    "    slice_idx = temp_data.shape[2] // 2  # Middle Y coordinate\n",
    "    \n",
    "    # Get consecutive frames\n",
    "    ground_truth_frames = []\n",
    "    for t_idx in range(test_start_idx, min(test_start_idx + total_frames_needed, test_end_idx)):\n",
    "        # Extract XZ slice at this timestep [X, Z]\n",
    "        slice_2d = temp_data[t_idx, :, slice_idx, :]  # [X, Z]\n",
    "        \n",
    "        # Downsample by factor of 2 (same as dataset)\n",
    "        slice_2d = slice_2d[::2, ::2]\n",
    "        \n",
    "        # Add channel dimension [1, X, Z]\n",
    "        slice_2d = slice_2d.unsqueeze(0)\n",
    "        ground_truth_frames.append(slice_2d)\n",
    "    \n",
    "    # Stack into tensor [T, 1, X, Z]\n",
    "    ground_truth = torch.stack(ground_truth_frames, dim=0)\n",
    "    \n",
    "    print(f\"\\nGround truth sequence shape: {ground_truth.shape}\")\n",
    "    print(f\"Temperature range: [{ground_truth.min():.1f}, {ground_truth.max():.1f}] K\")\n",
    "    print(f\"Frames loaded: {len(ground_truth_frames)}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"ERROR: Preprocessed file not found at {temp_path}\")\n",
    "    print(\"Please run scripts/preprocess_data.py first!\")\n",
    "    raise FileNotFoundError(f\"Missing {temp_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 4. Autoregressive Prediction\n",
    "\n",
    "Use the first 3 frames as initial context, then predict frames 4-5 autoregressively:\n",
    "- Frame 4: predict using frames [1, 2, 3]\n",
    "- Frame 5: predict using frames [2, 3, 4_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize predictions list with ground truth initial frames\n",
    "predictions = [ground_truth[i] for i in range(num_initial_frames)]\n",
    "\n",
    "print(f\"Starting autoregressive prediction...\")\n",
    "print(f\"Initial frames: 0-{num_initial_frames-1}\")\n",
    "print(f\"Predicting frames: {num_initial_frames}-{num_initial_frames + num_predictions - 1}\")\n",
    "print()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for step in range(num_predictions):\n",
    "        # Get last 3 frames as input (sequence_length=3)\n",
    "        input_frames = predictions[-3:]  # List of 3 tensors [1, H, W]\n",
    "        input_seq = torch.stack(input_frames, dim=0)  # [3, 1, H, W]\n",
    "        \n",
    "        # Add batch dimension and move to device\n",
    "        input_batch = input_seq.unsqueeze(0).to(device)  # [1, 3, 1, H, W]\n",
    "        \n",
    "        # Predict next frame\n",
    "        pred = model(input_batch)  # [1, 1, H, W]\n",
    "        \n",
    "        # Remove batch dimension and move to CPU\n",
    "        pred_frame = pred.squeeze(0).cpu()  # [1, H, W]\n",
    "        \n",
    "        # Append to predictions\n",
    "        predictions.append(pred_frame)\n",
    "        \n",
    "        frame_idx = num_initial_frames + step\n",
    "        gt_frame = ground_truth[frame_idx]\n",
    "        mse = ((pred_frame - gt_frame) ** 2).mean().item()\n",
    "        mae = (pred_frame - gt_frame).abs().mean().item()\n",
    "        \n",
    "        print(f\"Frame {frame_idx}: MSE = {mse:.2f} K², MAE = {mae:.2f} K\")\n",
    "\n",
    "# Stack predictions into tensor [T, 1, H, W]\n",
    "predictions_tensor = torch.stack(predictions, dim=0)\n",
    "\n",
    "print()\n",
    "print(f\"Predicted sequence shape: {predictions_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5. Visualize Results\n",
    "\n",
    "Plot ground truth, predictions, and error for all frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with 3 rows: ground truth, predictions, absolute error\n",
    "num_frames_to_plot = total_frames_needed\n",
    "fig, axes = plt.subplots(3, num_frames_to_plot, figsize=(2.5 * num_frames_to_plot, 8))\n",
    "\n",
    "cmap = colormaps['hot']\n",
    "vmin, vmax = 300, 4500  # Temperature range in Kelvin\n",
    "\n",
    "for i in range(num_frames_to_plot):\n",
    "    # Ground truth\n",
    "    gt = ground_truth[i, 0].cpu().numpy()  # [H, W]\n",
    "    im0 = axes[0, i].imshow(gt, cmap=cmap, vmin=vmin, vmax=vmax, aspect='auto')\n",
    "    axes[0, i].set_title(f\"Frame {i}\\n(Ground Truth)\", fontsize=10)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    pred = predictions_tensor[i, 0].cpu().numpy()  # [H, W]\n",
    "    im1 = axes[1, i].imshow(pred, cmap=cmap, vmin=vmin, vmax=vmax, aspect='auto')\n",
    "    \n",
    "    if i < num_initial_frames:\n",
    "        axes[1, i].set_title(f\"Frame {i}\\n(Initial Context)\", fontsize=10)\n",
    "    else:\n",
    "        axes[1, i].set_title(f\"Frame {i}\\n(Predicted)\", fontsize=10)\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Absolute error\n",
    "    error = np.abs(pred - gt)\n",
    "    im2 = axes[2, i].imshow(error, cmap='viridis', vmin=0, vmax=100, aspect='auto')\n",
    "    mae = error.mean()\n",
    "    axes[2, i].set_title(f\"MAE: {mae:.1f} K\", fontsize=10)\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "# Add colorbars\n",
    "fig.colorbar(im0, ax=axes[0, :], orientation='horizontal', pad=0.02, label='Temperature (K)')\n",
    "fig.colorbar(im1, ax=axes[1, :], orientation='horizontal', pad=0.02, label='Temperature (K)')\n",
    "fig.colorbar(im2, ax=axes[2, :], orientation='horizontal', pad=0.02, label='Absolute Error (K)')\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.savefig('../runs/2025-11-19_18-49-53/visualizations/autoregressive_prediction.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization saved to: ../runs/2025-11-19_18-49-53/visualizations/autoregressive_prediction.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 6. Error Analysis\n",
    "\n",
    "Analyze how error accumulates during autoregressive prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for each frame\n",
    "mse_per_frame = []\n",
    "mae_per_frame = []\n",
    "\n",
    "for i in range(total_frames_needed):\n",
    "    gt = ground_truth[i, 0]\n",
    "    pred = predictions_tensor[i, 0]\n",
    "    \n",
    "    mse = ((pred - gt) ** 2).mean().item()\n",
    "    mae = (pred - gt).abs().mean().item()\n",
    "    \n",
    "    mse_per_frame.append(mse)\n",
    "    mae_per_frame.append(mae)\n",
    "\n",
    "# Plot error evolution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# MSE plot\n",
    "ax1.plot(range(total_frames_needed), mse_per_frame, marker='o', linewidth=2)\n",
    "ax1.axvline(x=num_initial_frames - 0.5, color='red', linestyle='--', label='Start of predictions')\n",
    "ax1.set_xlabel('Frame Index', fontsize=12)\n",
    "ax1.set_ylabel('MSE (K²)', fontsize=12)\n",
    "ax1.set_title('Mean Squared Error vs Frame Index', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# MAE plot\n",
    "ax2.plot(range(total_frames_needed), mae_per_frame, marker='o', linewidth=2, color='orange')\n",
    "ax2.axvline(x=num_initial_frames - 0.5, color='red', linestyle='--', label='Start of predictions')\n",
    "ax2.set_xlabel('Frame Index', fontsize=12)\n",
    "ax2.set_ylabel('MAE (K)', fontsize=12)\n",
    "ax2.set_title('Mean Absolute Error vs Frame Index', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../runs/2025-11-19_18-49-53/visualizations/error_evolution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nError Statistics:\")\n",
    "print(f\"  Initial context (frames 0-{num_initial_frames-1}): MAE = {np.mean(mae_per_frame[:num_initial_frames]):.2f} K (should be ~0)\")\n",
    "print(f\"  Predicted frames ({num_initial_frames}-{total_frames_needed-1}): MAE = {np.mean(mae_per_frame[num_initial_frames:]):.2f} K\")\n",
    "print(f\"  Error increase per step: {(mae_per_frame[-1] - mae_per_frame[num_initial_frames]) / num_predictions:.2f} K/step\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lasernet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
